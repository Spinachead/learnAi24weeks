### langchain知识库项目开发
今天解决langgraphp获取完文档后再请求大模型 由于文档内容过多导致的模型胡言乱语


### 到今天终于解决了大模型胡言乱语的问题
产生问题的原因是其实是模板的问题，
这是产生问题的模板
```
                template = """你是一个严格的知识库问答助手。

【你的任务】
根据"【内容】"回答用户问题。

【回答规则】
1.参考内容回答
3. 如果知识库中没有答案，必须回答：我在提供的资料中没有找到相关答案

【知识库信息】
来源：{context}

【内容】：
{context}

【用户问题】
{question}

【请给出你的答案】
"""
```

使用此模板的回复内容是： [】【【：（   只有一些符号



这是正常的模板 回复是正常的
```
                template = """
                【指令】根据已知信息，简洁和专业的来回答问题。
                如果无法从中得到答案，请说 “根据已知信息无法回答该问题”，不允许在答案中添加编造成分，答案请使用中文。
                【已知信息】{context}
                【问题】{question}
                """
```

#### 为什么第一个模板回复有问题第二个回复就是正常的
1. template1给出了过多的标记和层级嵌套 如：【内容】 【用户问题】 这些层级嵌套 和多层结构。
2. 中文全角括号 【】 这些特殊字符消耗的tokenizer 开销过大 容易导致编码问题
3. 多层级标记 - 模型需要理解"任务" → "规则" → "信息" 的嵌套逻辑
4. qwen:1.8b 容量不足
5. Token 数过多 - ~100+ tokens，对 1.8B 参数模型来说太浪费上下文窗口

#### 修改正常后的template1
```
# 原则 1：最小化 token 使用
# 原则 2：避免重复变量
# 原则 3：避免多层级结构
# 原则 4：直接而非修饰性语言

template_optimized = """你是一个严格的知识库问答助手。

基于以下内容，简洁和专业地回答问题。无法回答则说：我无法基于提供的信息回答这个问题。

内容：
{context}

问题：{question}

答案："""
```

### 相关文档
1. https://docs.langchain.com/langsmith/prompt-engineering-quickstart 使用 ChatPromptTemplate 的正确方式
2. https://docs.langchain.com/langsmith/create-a-prompt   正确create a promtp
